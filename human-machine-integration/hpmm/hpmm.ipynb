{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Performance Monitoring Module (HPMM)\n",
    "Authors: Jiawei Chen & Ruoxin Xiong, Carnegie Mellon University\n",
    "\n",
    "Email: ruoxinx@andrew.cmu.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of HPMM Module\n",
    "This module uses data collected from ASU's Air Traffic Controller Simulation Experiments where three 25 minute approach scenarios were simulated - a baseline workload, a high workload under nominal conditions, and a high workload under off-nominal conditions. Information on these data can be found on the ASU ULI's website [here](https://uli.asu.edu/wp-content/uploads/2020/08/Presentation-AIAA-talk-2019-Task-3-Human-Systems-Integration.pdf). \n",
    "\n",
    "The sample data is collected from controller-in-the-loop simulation experiments during the air traffic control tasks. The performance measure of the ATC experiments in each scenario were Loss of Separation (LoS) where aircraft fail to maintain minimum separation distances in controlled airspace. This module uses LoS as an indicator of the air traffic controller's operational performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Installing the required Python packages\n",
    "\n",
    "The required Python packages for this module are:\n",
    "- ***[```catboost```]***(https://catboost.ai/docs/installation/python-installation-method-pip-install.html#python-installation-method-pip-install)\n",
    "- ***[```pandas```]***\n",
    "- ***[```numpy```]***\n",
    "- ***[```sklearn```]***\n",
    "\n",
    "In the Ubuntu or Anaconda terminal, execute ```conda install catboost pandas numpy sklearn```. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Processing and Visualizing ATC Data\n",
    "### Step 1a: Import ```human_data.csv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./human_data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1b. Downselect columns\n",
    "\n",
    "Drop specified columns of redundant variables for LoS prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['Ss', 'at_sec', 'condtn', 'ready_latency', 'query_latency', 'response_index', \n",
    "                 'los_dur_over5min','query_timed_out', 'ready_timed_out', 'ready_latency_adj',\n",
    "                 'cum_los_dur','stimuli', 'response_text', 'condtn_num', 'query']\n",
    "\n",
    "df.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1c: Transform LoS into binary class and fill NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If LoS > 1, impute to 1\n",
    "df.loc[df.los_freq>1,'los_freq']=1\n",
    "\n",
    "#If value in column is NaN, replace with mean of column\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1d: Define predictor and criterian \n",
    "Define predictor(X) and criterion(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['los_freq'])\n",
    "Y = df['los_freq']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2:  Training and testing LoS prediction models\n",
    "In this step, we aim to predict the occurrence of LoS with the various classification models:\n",
    "1. ```catboost``` Python package. ```catboost``` employs a machine learning based classifier. \n",
    "2. Support vector machines (SVM)\n",
    "3. Decision Tree\n",
    "4. k-Nearest Neighbors (KNN)\n",
    "5. Naive Bayes Classifier\n",
    "\n",
    "### Model Option 1: ```catboost``` model\n",
    "\n",
    "### Step2a: Divide data into train and test sets\n",
    "Split the dataset into 80% and 20% for training and testing, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=10)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2b: Define ```catboost``` model, loss function, and evaluation metric\n",
    "Here we use the ```CatBoostClassiifier``` model with a LogLoss loss function and Accuracy as the evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2c: Search for learning rate, depth, and L2 regularization\n",
    "The optimal model parameters for learning rate, depth, and L2 regularization are determined based on a grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grid options\n",
    "grid = {'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'depth': [4, 6, 10],\n",
    "        'l2_leaf_reg': [1, 3, 5, 7, 9],\n",
    "        } \n",
    "\n",
    "\n",
    "# Search grid\n",
    "model.grid_search(grid, X=X_train, y=y_train, verbose= 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2d: Determine best model parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: ```catboost``` Model Evaluation\n",
    "\n",
    "### Step3a: Prediction with test holdout data\n",
    "First we will predict the LoS output for X_test and compare with y_test. \n",
    "\n",
    "We will evaluate the model based on 3 criteria:\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3b: Visualize confusion matrix for test holdout data\n",
    "A confusion matrix gives visual indication of accuracy at predicting the two labels\n",
    "- label(0): no LOS\n",
    "- label(1): LOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(model, X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Assessing feature importance\n",
    "For each of the 11 features in the data, a feature importance plot shows how much the prediction changes if the feature value changes. The bigger the value of the feature importance, the bigger the expected change to the prediction value. Feature importance values are normalized to [0, 100].\n",
    "\n",
    "### Step 4a: Get feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_ = model.feature_importances_\n",
    "\n",
    "fea_name = list(X.columns)\n",
    "fea_name = [str(j) for j in fea_name]\n",
    "\n",
    "for f_name,f in zip(fea_name,fea_):\n",
    "    print(f_name,':',f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Assess Other Modeling Options\n",
    "### Model 2: Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(gamma=2, C=1)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "pred = svm.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(svm, X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=5)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "pred = dt.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(dt, X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: k-Nearest Neighbors (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "pred = knn.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(knn, X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nn = GaussianNB()\n",
    "nn.fit(X_train, y_train)\n",
    "\n",
    "pred = nn.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(nn, X_test, y_test) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
