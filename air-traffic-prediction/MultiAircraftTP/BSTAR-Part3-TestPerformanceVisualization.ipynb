{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Spatiotemporal Graph Transformer Network (B-STAR) for Multi-Aircraft Trajectory Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: B-STAR Results Visualization, Validation and Statistical Analysis\n",
    "\n",
    "Author: Yutian Pang, Arizona State University\n",
    "\n",
    "Email: yutian.pang@asu.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module Requirements\n",
    "\n",
    "This Jupyter notenook has been tested with:\n",
    "- Ubuntu 20.04 LTS\n",
    "- Python 3.8.5 with Anaconda\n",
    "- Google Cloud API key (Can be obtained at https://developers.google.com/maps/documentation/javascript/get-api-key)\n",
    "\n",
    "The packages required to run this module are:\n",
    "- **[```pickle```]** (https://docs.python.org/3/library/pickle.html#module-pickle)\n",
    "    - Converts a Python object into a byte stream to store it in a file/database and transport data over the network. Pickle is part of the standard Python library, no installation needed.\n",
    "- **[```numpy```]**\n",
    "    - Provides support for array operations \n",
    "- **[```shapely```]**(https://pypi.org/project/Shapely/)\n",
    "    -  For manipulation and analysis of planar geometric objects.\n",
    "- **[```attrs```]**(https://www.attrs.org/en/stable/)\n",
    "    -  Simplyifies the definition of classes and attributes and streamlines class object operations.\n",
    "- **[```matplotlib```]**\n",
    "    - Main plotting functionalities\n",
    "- **[```bokeh```]** \n",
    "    - For creating interactive visualizations within a web browser. Requires Google Cloud API key\n",
    "- **[```pyspark```]**(http://spark.apache.org/docs/latest/api/python/getting_started/index.html)\n",
    "    - This is the Python API for Apache Spark. We will be using the distributed processing features and backend SQL queries for structured data.\n",
    "- **[```apache-sedona```]**(https://sedona.apache.org/)\n",
    "    - Formerly Geospark, Apache Sedona extends the Resilient Distributed Dataset (RDD), the core data structure in Apache Spark, to accommodate big geospatial data in a cluster environment.\n",
    "    \n",
    "```pickle```, ```numpy```, ```matplotlib```and ```bokeh```are part of the standard Python library (no installation needed). To install the ```pyspark```, ```shapely```, ```attrs``` and ```apache-sedona``` packages simultaneously, execute ```pip install pyspark shapely attrs apache-sedona``` in the Ubuntu or Anaconda terminal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'YOUR GOOGLE CLOUD API KEY HERE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Validation Data\n",
    "We begin by loading the data set that will be used to test the performance of the B-STAR model. We trained the model with a six-day data set and will be testing it using a 1-day set.\n",
    "\n",
    "We load and save the test data into two Python dictionaries: ```frameped_dict``` for the entire testset and ```trajec_dict``` for processed batch-by-batch data. The dictionaries have the following attributes:\n",
    "\n",
    "- frameped_dict: \n",
    "    - dataset_index\n",
    "    - frame_index\n",
    "    - aircraft index list\n",
    "- trajec_dict:\n",
    "    - dataset_index\n",
    "    - aircraft index\n",
    "    - trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cache(data_file):\n",
    "    f = open(data_file, 'rb')\n",
    "    raw_data = pickle.load(f)\n",
    "    f.close()\n",
    "    return raw_data\n",
    "def load_dict(data_file):\n",
    "    f = open(data_file, 'rb')\n",
    "    raw_data = pickle.load(f)\n",
    "    f.close()\n",
    "    frameped_dict = raw_data[0]\n",
    "    traject_dict = raw_data[1]\n",
    "\n",
    "    return frameped_dict, traject_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_file = \"test_result/train_trajectories.cpkl\"\n",
    "# train_batch_cache = \"test_result/train_batch_cache.cpkl\"\n",
    "# train_frameped_dict, train_pedtraject_dict = load_dict(train_data_file)\n",
    "# trainbatch, trainbatchnums, _, _ = load_cache(train_batch_cache)\n",
    "\n",
    "test_data_file = \"test_result/test_trajectories.cpkl\"\n",
    "test_batch_cache = \"test_result/test_batch_cache.cpkl\"\n",
    "test_frameped_dict, test_traject_dict = load_dict(test_data_file)\n",
    "testbatch, testbatchnums, _, _ = load_cache(test_batch_cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the (pre-trained) B-STAR results\n",
    "We now load the results of the pre-trained B-STAR model. During the training process, we identify the best model by evaluating model performance using the following metrics: \n",
    "- Average Displacement Error (ADE). \n",
    "- Final Displacement Error (FDE).\n",
    "\n",
    "In this experiment, the model with best performance was reached using the following parameters:\n",
    "- The model is trained with $t_{obs}=12$, $t_{pred}=8$\n",
    "- Training spanned 300 epochs, with best performance reached at epoch 290.\n",
    "    - Best_ADE=0.003, Best_FDE=0.006 at Epoch 290"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_batch_cache = \"test_result/all_test_output_290.cpkl\"\n",
    "result= load_cache(pred_batch_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Batch in Testset: {}\".format(len(testbatch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indentifying Neighbors within a Batch of Test Data\n",
    "Here we show how the neighbor data is stored in each batch of the data. We first select a batch index in the test (validation) set. Then we plot all the neighbors in this batch. Neighbor data is stored in a binary tensor <b>nei_list_b</b> called adjacency matrix (<b>A</b>) in graph neural networks. The dimension of (<b>A</b>) denotes the total number of trajectories in this batch. A value of 1 indicates that the corresponding x-y indices for this component are neighbors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nei_list_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_batch_number = 4\n",
    "batch_data, batch_id = testbatch[i_batch_number]\n",
    "\n",
    "nodes_batch_b, seq_list_b, nei_list_b, nei_num_b, batch_pednum = batch_data\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.cm as cm\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(nei_list_b[0], cmap=cm.binary, aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_batch_b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The neighbors (group of trajectories) selected to display\n",
    "\n",
    "To visualize the adjacency matrix for the validation data, we select a range of neighbor indices to display:\n",
    "\n",
    "- idx_start\n",
    "    - trajectory start index\n",
    "- idx_end\n",
    "    - trajectory end index   \n",
    "    \n",
    "In the example below, we select three agents, each pairs of them are determined as neighbors (An agent cannot be the neighbor of itself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_start = 37\n",
    "# idx_end = 41\n",
    "\n",
    "idx_start = 41\n",
    "idx_end = 44\n",
    "\n",
    "plt.imshow(nei_list_b[0][idx_start:idx_end,idx_start:idx_end],cmap=cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gound Truth Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Entire Batch\n",
    "This is to visualize the entire batch of the data into one plot. The timelabel is encrypted to timestamps from 1 to 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ -d cache ]; \n",
    "then \n",
    "   echo \"path exists\"\n",
    "else\n",
    "   mkdir cache\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from matplotlib import cm\n",
    "import time\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "r = 0.2\n",
    "colors = cm.rainbow(np.linspace(0, 1, nodes_batch_b.shape[1]))\n",
    "for i in range(20):\n",
    "    clear_output(wait=True)\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    \n",
    "    plt.axis([-84.4278640-r, -84.4278640+r, 33.6366996-r, 33.6366996+r])\n",
    "    plt.title(\"Testset (Omit Timestamp)\", fontsize=18)\n",
    "    plt.xlabel(\"Longitude/$^\\circ$\", fontsize=18)\n",
    "    plt.ylabel(\"Latitude/$^\\circ$\", fontsize=18)\n",
    "    plt.subplots_adjust(left=0.17, right=0.97, top=0.9, bottom=0.12)\n",
    "\n",
    "    plt.scatter(*nodes_batch_b[i].T, c=colors, s=10)  \n",
    "    plt.savefig('cache/{}.png'.format(i), dpi=300)\n",
    "\n",
    "    plt.show()\n",
    "    #time.sleep(0.1)\n",
    "    \n",
    "    \n",
    "buffer_groud_truth = nodes_batch_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Save GIF\n",
    "This is to create the gif file of the above animation in jupyter through Bash script. \n",
    "\n",
    "- jupyter bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%bash\n",
    "! (cd cache;\\\n",
    "convert -delay 20 -loop 0 *.png ground_truth.gif;\\\n",
    "find . -name \"*.png\" -type f -delete;\\\n",
    "echo \"gif saved\";)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google MAP CLOUD API\n",
    "We also built an interactive geographical visualization alternative to the previous plots. We use Bokeh and the powerful Google MAP Cloud API to help us achieve this goal. This time, we plot the whole trajectory sequence instead of an animation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh\n",
    "from bokeh.io import output_file, show, export_png\n",
    "from bokeh.models import GMapOptions\n",
    "from bokeh.plotting import gmap\n",
    "bokeh.io.reset_output()\n",
    "bokeh.io.output_notebook()\n",
    "\n",
    "#output_file(\"gmap.html\")\n",
    "\n",
    "map_options = GMapOptions(lat=33.6366996, lng=-84.4278640, map_type=\"hybrid\", zoom=11)\n",
    "p = gmap(api_key, map_options, title=\"KATL on Aug 7th, 2019\")\n",
    "\n",
    "for i in range(buffer_groud_truth.shape[1]):\n",
    "    lat = buffer_groud_truth[:, i, 0].tolist()\n",
    "    lon = buffer_groud_truth[:, i, 1].tolist()\n",
    "    p.circle(x=lat, y=lon, size=5, fill_color=\"white\", fill_alpha=0.8)\n",
    "    #p.line(x=lat, y=lon, line_width=2)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "\n",
    "# options = webdriver.ChromeOptions()\n",
    "# options.add_argument('--headless')\n",
    "# options.add_argument('--no-sandbox')\n",
    "# driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# p.background_fill_color = None\n",
    "# p.border_fill_color = None\n",
    "\n",
    "# export_png(p, filename=\"ground_truth.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Selected Neighbors Data\n",
    "The visualization of the neighbors set we selected above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from matplotlib import cm\n",
    "import time\n",
    "\n",
    "buffer_groud_truth = nodes_batch_b[:,idx_start:idx_end,:]\n",
    "colors = cm.rainbow(np.linspace(0, 1, buffer_groud_truth.shape[1]))\n",
    "\n",
    "for i in range(20):\n",
    "    clear_output(wait=True)\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    plt.axis([-84.4278640-r, -84.4278640+r, 33.6366996-r, 33.6366996+r])\n",
    "    plt.title(\"Neighbors Set (Ground Truth)\", fontsize=18)\n",
    "    plt.xlabel(\"Longitude/$^\\circ$\", fontsize=18)\n",
    "    plt.ylabel(\"Latitude/$^\\circ$\", fontsize=18)\n",
    "    plt.subplots_adjust(left=0.17, right=0.97, top=0.9, bottom=0.12)\n",
    "\n",
    "    plt.scatter(*buffer_groud_truth[i].T, c=colors, s=30)\n",
    "    plt.savefig('cache/{}.png'.format(i), dpi=300)\n",
    "\n",
    "    plt.show()\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd cache \n",
    "convert -delay 20 -loop 0 *.png neighbor_set_ground_truth.gif\n",
    "find . -name \"*.png\" -type f -delete\n",
    "echo \"gif saved\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_file, show\n",
    "from bokeh.models import ColumnDataSource, GMapOptions\n",
    "from bokeh.plotting import gmap\n",
    "bokeh.io.reset_output()\n",
    "bokeh.io.output_notebook()\n",
    "\n",
    "#output_file(\"gmap.html\")\n",
    "\n",
    "map_options = GMapOptions(lat=33.6366996, lng=-84.4278640, map_type=\"roadmap\", zoom=11)\n",
    "p = gmap(api_key, map_options, title=\"KATL\")\n",
    "\n",
    "for i in range(buffer_groud_truth.shape[1]):\n",
    "    lat = buffer_groud_truth[:, i, 0].tolist()\n",
    "    lon = buffer_groud_truth[:, i, 1].tolist()\n",
    "    p.circle(x=lat, y=lon, size=5, fill_color=\"red\", fill_alpha=1)\n",
    "    #p.line(x=lat, y=lon, line_width=2)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data Feeded into B-STAR Training\n",
    "In this section, we show the reader what is the actual data feeded into the B-STAR model during the training process. Simply speaking, the coordinate system is defined at origin $(x_t, y_t)$ where $t$ is the last observation timestamp. The shifting of the original data is performed at each timestamp. The function ```rotate_shift_batch``` is the implementation, which an alternative to random rotate the shifted coordinates (```ifrotate=False``` in our case). This is considered as the normalization of the inputs in standard deep learning procedures.\n",
    "\n",
    "- Shifting is performed to the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_shift_batch(batch_data, ifrotate=True):\n",
    "    '''\n",
    "    Random ration and zero shifting.\n",
    "    '''\n",
    "    batch, seq_list, nei_list, nei_num, batch_pednum = batch_data\n",
    "\n",
    "    # rotate batch\n",
    "    if ifrotate:\n",
    "        th = random.random() * np.pi\n",
    "        cur_ori = batch.copy()\n",
    "        batch[:, :, 0] = cur_ori[:, :, 0] * np.cos(th) - cur_ori[:, :, 1] * np.sin(th)\n",
    "        batch[:, :, 1] = cur_ori[:, :, 0] * np.sin(th) + cur_ori[:, :, 1] * np.cos(th)\n",
    "        \n",
    "    # get shift value\n",
    "    s = batch[11 - 1]\n",
    "\n",
    "    shift_value = np.repeat(s.reshape((1, -1, 2)), 20, 0)\n",
    "    batch_data = batch, batch - shift_value, shift_value, seq_list, nei_list, nei_num, batch_pednum\n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data_b = rotate_shift_batch(batch_data, ifrotate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_abs, batch_norm, shift_value, seq_list, nei_list, nei_num, batch_pednum = batch_data_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from matplotlib import cm\n",
    "import time\n",
    "\n",
    "buffer = batch_norm[:,idx_start:idx_end,:]\n",
    "colors = cm.rainbow(np.linspace(0, 1, buffer.shape[1]))\n",
    "\n",
    "for i in range(20):\n",
    "    clear_output(wait=True)\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    plt.axis([-r, r, -r, r])\n",
    "    plt.title(\"Neighbors Set (Normalized)\", fontsize=18)\n",
    "    plt.xlabel(\"Longitude/$^\\circ$\", fontsize=18)\n",
    "    plt.ylabel(\"Latitude/$^\\circ$\", fontsize=18)\n",
    "    plt.subplots_adjust(left=0.17, right=0.97, top=0.9, bottom=0.12)\n",
    "\n",
    "    plt.scatter(*buffer[i].T, c=colors, s=30) \n",
    "    plt.savefig('cache/{}.png'.format(i), dpi=300)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd cache \n",
    "convert -delay 20 -loop 0 *.png normalized_input.gif\n",
    "find . -name \"*.png\" -type f -delete\n",
    "echo \"gif saved\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shift the prediction back to the orginal range\n",
    "We visualize the test result from the model output here, after shifting the output back to the original WGS84 coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from matplotlib import cm\n",
    "import time\n",
    "\n",
    "buffer_pred = result['test_mean'][i_batch_number][:,idx_start:idx_end,:].cpu() + shift_value[1:,idx_start:idx_end,:]\n",
    "\n",
    "aa = np.array(result['test_mean'][i_batch_number].cpu())\n",
    "colors = cm.rainbow(np.linspace(0, 1, buffer_pred.shape[1]))\n",
    "\n",
    "for i in range(19):\n",
    "    clear_output(wait=True)\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    plt.axis([-84.4278640-r,-84.4278640+r,33.6366996-r,33.6366996+r])\n",
    "    plt.title(\"Neighbors Set (Prediction)\", fontsize=18)\n",
    "    plt.xlabel(\"Longitude/$^\\circ$\", fontsize=18)\n",
    "    plt.ylabel(\"Latitude/$^\\circ$\", fontsize=18)\n",
    "    plt.subplots_adjust(left=0.17, right=0.97, top=0.9, bottom=0.12)\n",
    "\n",
    "    plt.scatter(*buffer_pred[i].T, c=colors, s=50) \n",
    "    plt.savefig('cache/{}.png'.format(i), dpi=300)\n",
    "    \n",
    "    #plt.axis([np.min(aa[:,idx_start:idx_end,0])-1,np.max(aa[:,idx_start:idx_end,0])+1,np.min(aa[:,idx_start:idx_end,1])-1,np.max(aa[:,idx_start:idx_end,1])+1])\n",
    "    plt.show()\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd cache \n",
    "convert -delay 50 -loop 0 *.png prediction.gif \n",
    "find . -name \"*.png\" -type f -delete\n",
    "echo \"gif saved\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_file, show\n",
    "from bokeh.models import ColumnDataSource, GMapOptions\n",
    "from bokeh.plotting import gmap\n",
    "bokeh.io.reset_output()\n",
    "bokeh.io.output_notebook()\n",
    "\n",
    "#output_file(\"gmap.html\")\n",
    "\n",
    "map_options = GMapOptions(lat=33.6366996, lng=-84.4278640, map_type=\"roadmap\", zoom=11)\n",
    "p = gmap(api_key, map_options, title=\"KATL\")\n",
    "\n",
    "for i in range(buffer_pred.shape[1]):\n",
    "    lat = buffer_pred[:, i, 0].tolist()\n",
    "    lon = buffer_pred[:, i, 1].tolist()\n",
    "    p.circle(x=lat, y=lon, size=5, fill_color=\"red\", fill_alpha=0.8, legend_label='Prediction Mean')\n",
    "    #p.line(x=lat, y=lon, line_width=2)\n",
    "    \n",
    "    lat = buffer_groud_truth[:, i, 0].tolist()\n",
    "    lon = buffer_groud_truth[:, i, 1].tolist()\n",
    "    p.circle(x=lat, y=lon, size=5, fill_color=\"blue\", fill_alpha=0.8, legend_label='Ground Truth')\n",
    "    p.legend.location = \"top_left\"\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction with Confidence Ellipse, after shifting\n",
    "The model also generates the test variance on latitude and longitude dimensions. We can put a $3\\sigma$ uncertainty ellipse on each prediction point. We notice that the uncertainty is minimal at the observation timestamps and keeps increasing in the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['test_var'][i_batch_number][:,idx_start:idx_end,:].cpu().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from matplotlib import cm\n",
    "import time\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "mean =result['test_mean'][i_batch_number][:,idx_start:idx_end,:].cpu() + shift_value[1:,idx_start:idx_end,:]\n",
    "std = np.sqrt(result['test_var'][i_batch_number][:,idx_start:idx_end,:].cpu())\n",
    "\n",
    "aa = np.array(result['test_mean'][i_batch_number].cpu())\n",
    "colors = cm.rainbow(np.linspace(0, 1, mean.shape[1]))\n",
    "\n",
    "for i in range(19):\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    \n",
    "    plt.axis([-84.4278640-r, -84.4278640+r, 33.6366996-r, 33.6366996+r])\n",
    "    plt.scatter(*buffer_pred[i].T, c=colors, s=30) \n",
    "    plt.title(\"Neighbors Set (Prediction)\", fontsize=18)\n",
    "    plt.xlabel(\"Longitude/$^\\circ$\", fontsize=18)\n",
    "    plt.ylabel(\"Latitude/$^\\circ$\", fontsize=18)\n",
    "    plt.subplots_adjust(left=0.17, right=0.97, top=0.9, bottom=0.12)\n",
    "\n",
    "    # draw confidence ellipse\n",
    "    ells = [Ellipse(xy=[mean[i, j, 0], mean[i, j, 1]], width = 3 * std[i, j, 0], height = 3 * std[i, j, 1], \n",
    "                           angle=0, fill=False)\n",
    "#                 angle=90-np.rad2deg(\n",
    "#                     np.arctan((self.pred_traj_mean[idx, i, 0] - self.pred_traj_mean[idx, i-1, 0]) /\n",
    "#                               (self.pred_traj_mean[idx, i, 1] - self.pred_traj_mean[idx, i-1, 1]))))\n",
    "           for j in range(mean.shape[1])]\n",
    "    \n",
    "#     for e in ells:\n",
    "#         ax.add_artist(e)\n",
    "#         e.set_clip_box(ax.bbox)\n",
    "#         e.set_alpha(1)\n",
    "#         e.set_facecolor('r')\n",
    "    \n",
    "    for e in ells:\n",
    "        ax.add_artist(e)\n",
    "        e.set_clip_box(ax.bbox)\n",
    "        e.set_alpha(0.5)\n",
    "        #e.set_facecolor('b')\n",
    "    \n",
    "    #plt.axis([np.min(aa[:,idx_start:idx_end,0])-1,np.max(aa[:,idx_start:idx_end,0])+1,np.min(aa[:,idx_start:idx_end,1])-1,np.max(aa[:,idx_start:idx_end,1])+1])\n",
    "    plt.savefig('cache/{}.png'.format(i), dpi=300)\n",
    "\n",
    "    plt.show()\n",
    "    time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd cache \n",
    "convert -delay 20 -loop 0 *.png prediction_uq.gif\n",
    "find . -name \"*.png\" -type f -delete\n",
    "echo \"gif saved\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification of Prediction Variance \n",
    "### Increasing since $t_{obs}=12$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_obs = 12\n",
    "t_all = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.plot(np.array(std[:, :, 0]), '-^')\n",
    "plt.plot(np.array(std[:, :, 1]), '-*')\n",
    "\n",
    "#plt.plot(np.array(result['test_var'][i_batch_number][:, idx_start:idx_end, 0].cpu()))\n",
    "plt.axvline(x=t_obs-1, ymin=0, ymax=1, c='red')\n",
    "ax.axvspan(0, t_obs-1, alpha=0.1, color='red')\n",
    "ax.axvspan(t_obs-1, t_all-2, alpha=0.2, color='y')\n",
    "\n",
    "plt.xlim(0, t_all-2)\n",
    "plt.xlabel('Timestamp (Start Point not Shown)', fontsize=18)\n",
    "plt.ylabel('$\\sigma$', fontsize=18)\n",
    "\n",
    "blue_star = mlines.Line2D([], [], color='black', marker='*', linestyle='None',\n",
    "                          markersize=10, label='Longitude')\n",
    "purple_triangle = mlines.Line2D([], [], color='black', marker='^', linestyle='None',\n",
    "                          markersize=10, label='Latitude')\n",
    "plt.legend(handles=[blue_star, purple_triangle])\n",
    "\n",
    "plt.title('Latitude/$^\\circ$, Longitude/$^\\circ$', fontsize=18)\n",
    "\n",
    "plt.savefig('std_all.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.plot(np.array(std[:, :, 0]), '-^')\n",
    "\n",
    "#plt.plot(np.array(result['test_var'][i_batch_number][:, idx_start:idx_end, 0].cpu()))\n",
    "plt.axvline(x=t_obs-1, ymin=0, ymax=1, c='red')\n",
    "ax.axvspan(0, t_obs-1, alpha=0.1, color='red')\n",
    "ax.axvspan(t_obs-1, t_all-2, alpha=0.2, color='y')\n",
    "\n",
    "red_patch = mpatches.Patch(color='red' ,alpha=0.1, label='Observations')\n",
    "blue_patch = mpatches.Patch(color='yellow', alpha=0.2, label='Predictions')\n",
    "plt.legend(handles=[red_patch, blue_patch])\n",
    "\n",
    "\n",
    "plt.xlim(0, t_all-2)\n",
    "plt.xlabel('Timestamp (Start Point not Shown)', fontsize=18)\n",
    "plt.ylabel('$\\sigma_{lat}$', fontsize=18)\n",
    "plt.title('Latitude/$^\\circ$', fontsize=18)\n",
    "plt.savefig('std_lat.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot(np.array(std[:, :, 1]), '-*')\n",
    "#plt.plot(np.array(result['test_var'][i_batch_number][:, idx_start:idx_end, 0].cpu()))\n",
    "plt.axvline(x=t_obs-1, ymin=0, ymax=1, c='red')\n",
    "ax.axvspan(0, t_obs-1, alpha=0.1, color='red')\n",
    "ax.axvspan(t_obs-1, t_all-2, alpha=0.2, color='y')\n",
    "\n",
    "red_patch = mpatches.Patch(color='red' ,alpha=0.1, label='Observations')\n",
    "blue_patch = mpatches.Patch(color='yellow', alpha=0.2, label='Predictions')\n",
    "plt.legend(handles=[red_patch, blue_patch])\n",
    "\n",
    "plt.xlim(0, t_all-2)\n",
    "plt.xlabel('Timestamp (Start Point not Shown)', fontsize=18)\n",
    "plt.ylabel('$\\sigma_{lon}$', fontsize=18)\n",
    "plt.title('Longitude/$^\\circ$', fontsize=18)\n",
    "plt.savefig('std_lon.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigations - Sensitivity\n",
    "As we mentioned, the parameters such as $t_{obs}$, $t_{pred}$ can be changed. Here we investigate the sensitivity of the propose model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametric Study on Prediction-Observation Ratio\n",
    "Prediction-Observation Ratio (PO-Ratio) is simply the ratio between prediction time horizon and observation time horizon. We've got the model ADE and FDE with 5 different PO-Ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_length = [12, 10, 8, 6, 4]\n",
    "pred_length = [8, 10, 12, 14, 16]\n",
    "\n",
    "ADE = [0.016, 0.016, 0.017, 0.022, 0.033]\n",
    "FDE = [0.033, 0.036, 0.040, 0.049, 0.062]\n",
    "\n",
    "ratio = [j / i for i, j in zip(obs_length, pred_length)]\n",
    "ratio = [round(x, 2) for x in ratio]\n",
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "width = 0.4\n",
    "plt.bar(np.arange(len(ratio)) - 0.5*width, ADE, width=width, label='ADE', color = 'blue', alpha=0.5)\n",
    "plt.bar(np.arange(len(ratio)) + 0.5*width, FDE, width=width, label='FDE', color = 'red', alpha=0.3)\n",
    "plt.xticks([0, 1, 2, 3, 4], ratio)\n",
    "plt.xlabel('$\\Theta$')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.title('Prediction-Obervation Ratio $\\Theta$')\n",
    "plt.savefig('ratio.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametric Study on Neighbor Distance Threshold\n",
    "The distance of two WGS84 coordinate is calculated with Havasine formula,\n",
    "$d = 2R \\arcsin (\\sqrt{\\sin^2(\\frac{Y_a - Y_b}{2})+\\cos(Y_a)\\cos(Y_b)\\sin^2(\\frac{X_a - X_b}{2})})$\n",
    "\n",
    "The threshold value (in kilometers) is used to determine the adjacency matrix mentioned above. If at a timestamp t, the coordinate distance d between two agents is lower than the threshold value, we fill the adjacency matrix with a number $1$, otherwise $0$. \n",
    "\n",
    "In this section, we want to study the impact of the threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_threshold = [10, 20, 30]\n",
    "ADE = [0.016, 0.015, 0.016]\n",
    "FDE = [0.033, 0.029, 0.033]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.4\n",
    "\n",
    "plt.bar(np.arange(len(d_threshold)) - 0.5*width, ADE, width=width, label='ADE', color = 'blue', alpha = 0.5)\n",
    "plt.bar(np.arange(len(d_threshold)) + 0.5*width, FDE, width=width, label='FDE', color = 'red', alpha = 0.3)\n",
    "plt.xticks([0, 1, 2], d_threshold)\n",
    "plt.xlabel('$\\zeta$')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Neighboring Threshold $\\zeta$')\n",
    "plt.savefig('neighbor.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work Performed\n",
    "- We developed a state-of-the-art uncertainty aware data-driven multi-agent interactive trajectory prediction model trained with real-world data.\n",
    "- We verify the correctness of mean prediction, and prediction variance of the propose model using the test dataset.\n",
    "- We perform sensitivity study to quantify the impact of Predictin Observation Ratio and Neighboring Threshold $\\zeta$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Usage\n",
    "- The propose model is suitable for any radar-based location tracking autonomous systems to perform,\n",
    "    - Accurate 4D location time-series forecasting with uncertainties, \n",
    "    - Early separation violation warning system"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
